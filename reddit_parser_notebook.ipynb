{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🤖 Reddit Parser з AI Аналізом\n",
        "\n",
        "Цей notebook дозволяє:\n",
        "- 📊 Парсити публікації та коментарі Reddit\n",
        "- 🧠 Аналізувати дані через LLM\n",
        "- 💡 Генерувати нові ідеї постів\n",
        "- 📈 Створювати детальну аналітику\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔧 Налаштування та імпорти\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Встановлення залежностей (запустіть один раз)\n",
        "%pip install praw python-dotenv requests openpyxl pandas openai httpx backoff nest-asyncio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import praw\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import asyncio\n",
        "import openai\n",
        "import backoff\n",
        "import nest_asyncio\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional\n",
        "from collections import Counter\n",
        "import re\n",
        "\n",
        "# Дозволяємо вкладені event loops для Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"✅ Імпорти завершено\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🌍 Глобальні налаштування\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 🎯 ГЛОБАЛЬНІ НАЛАШТУВАННЯ - РЕДАГУЙТЕ ТУТ\n",
        "\n",
        "# Сабреддіти для парсингу\n",
        "TARGET_SUBREDDITS = [\n",
        "    'Python',           # Python programming\n",
        "    'MachineLearning',  # Machine learning\n",
        "    'programming',      # General programming\n",
        "    'artificial',       # Artificial intelligence\n",
        "    'technology'        # Technology\n",
        "]\n",
        "\n",
        "# Сабреддіти для генерації контенту\n",
        "CONTENT_GENERATION_SUBREDDITS = [\n",
        "    'Python',\n",
        "    'learnpython',\n",
        "    'MachineLearning'\n",
        "]\n",
        "\n",
        "# Налаштування парсингу\n",
        "POSTS_PER_SUBREDDIT = 15  # Кількість постів з кожного сабреддіта\n",
        "SORT_BY = 'hot'  # 'hot', 'new', 'top', 'rising'\n",
        "COMMENTS_PER_POST = 10  # Кількість коментарів до кожного поста\n",
        "TEXT_LIMIT = 2000  # Ліміт символів для текстів (None = без ліміту)\n",
        "\n",
        "# Налаштування LLM\n",
        "LLM_MODEL = 'google/gemini-2.5-flash-lite-preview-06-17'\n",
        "MAX_CONCURRENT_REQUESTS = 30  # Кількість одночасних запитів (зменшено для стабільності)\n",
        "IDEAS_PER_SUBREDDIT = 2  # Кількість ідей для кожного сабреддіта\n",
        "MAX_TOKENS = 2500  # Максимальна кількість токенів для відповіді\n",
        "TIMEOUT_SECONDS = 90  # Час очікування відповіді (секунди)\n",
        "ENABLE_CONTINUATION = True  # Увімкнути догенерацію при обрізанні\n",
        "\n",
        "# API ключі (створіть файл .env або введіть тут)\n",
        "REDDIT_CLIENT_ID = os.getenv('REDDIT_CLIENT_ID', 'your_client_id_here')\n",
        "REDDIT_CLIENT_SECRET = os.getenv('REDDIT_CLIENT_SECRET', 'your_client_secret_here')\n",
        "OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY', 'your_openrouter_key_here')\n",
        "\n",
        "print(f\"🎯 Налаштовано парсинг {len(TARGET_SUBREDDITS)} сабреддітів\")\n",
        "print(f\"📊 Буде спарсено {POSTS_PER_SUBREDDIT * len(TARGET_SUBREDDITS)} постів\")\n",
        "print(f\"💡 Буде згенеровано {IDEAS_PER_SUBREDDIT * len(CONTENT_GENERATION_SUBREDDITS)} ідей\")\n",
        "print(f\"🤖 LLM модель: {LLM_MODEL}\")\n",
        "print(f\"🔧 Максимум токенів: {MAX_TOKENS}, Timeout: {TIMEOUT_SECONDS}s\")\n",
        "print(f\"🔄 Догенерація: {'Увімкнена' if ENABLE_CONTINUATION else 'Вимкнена'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📊 Парсинг Reddit даних\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_reddit_data(subreddits, posts_limit, sort_by, comments_limit, text_limit):\n",
        "    \"\"\"\n",
        "    Парсинг Reddit даних з коментарями\n",
        "    \"\"\"\n",
        "    # Ініціалізація Reddit API\n",
        "    reddit = praw.Reddit(\n",
        "        client_id=REDDIT_CLIENT_ID,\n",
        "        client_secret=REDDIT_CLIENT_SECRET,\n",
        "        user_agent='RedditParser/1.0'\n",
        "    )\n",
        "    \n",
        "    all_posts = []\n",
        "    all_comments = []\n",
        "    \n",
        "    for subreddit_name in subreddits:\n",
        "        print(f\"📊 Парсинг r/{subreddit_name}...\")\n",
        "        \n",
        "        try:\n",
        "            subreddit = reddit.subreddit(subreddit_name)\n",
        "            \n",
        "            # Вибір методу сортування\n",
        "            if sort_by == 'hot':\n",
        "                posts = subreddit.hot(limit=posts_limit)\n",
        "            elif sort_by == 'new':\n",
        "                posts = subreddit.new(limit=posts_limit)\n",
        "            elif sort_by == 'top':\n",
        "                posts = subreddit.top(limit=posts_limit)\n",
        "            else:\n",
        "                posts = subreddit.hot(limit=posts_limit)\n",
        "            \n",
        "            post_count = 0\n",
        "            for post in posts:\n",
        "                # Обробка тексту поста\n",
        "                selftext = post.selftext\n",
        "                if text_limit and len(selftext) > text_limit:\n",
        "                    selftext = selftext[:text_limit] + '...'\n",
        "                \n",
        "                post_data = {\n",
        "                    'post_id': post.id,\n",
        "                    'title': post.title,\n",
        "                    'author': str(post.author) if post.author else '[deleted]',\n",
        "                    'score': post.score,\n",
        "                    'upvote_ratio': post.upvote_ratio,\n",
        "                    'num_comments': post.num_comments,\n",
        "                    'created_utc': datetime.fromtimestamp(post.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                    'url': post.url,\n",
        "                    'permalink': f\"https://reddit.com{post.permalink}\",\n",
        "                    'selftext': selftext,\n",
        "                    'selftext_length': len(post.selftext),\n",
        "                    'subreddit': str(post.subreddit),\n",
        "                    'is_video': post.is_video,\n",
        "                    'over_18': post.over_18,\n",
        "                    'gilded': post.gilded\n",
        "                }\n",
        "                all_posts.append(post_data)\n",
        "                \n",
        "                # Парсинг коментарів до поста\n",
        "                if comments_limit > 0:\n",
        "                    try:\n",
        "                        post.comments.replace_more(limit=0)\n",
        "                        comment_count = 0\n",
        "                        \n",
        "                        for comment in post.comments.list():\n",
        "                            if comment_count >= comments_limit:\n",
        "                                break\n",
        "                                \n",
        "                            if hasattr(comment, 'body'):\n",
        "                                comment_body = comment.body\n",
        "                                if text_limit and len(comment_body) > text_limit:\n",
        "                                    comment_body = comment_body[:text_limit] + '...'\n",
        "                                \n",
        "                                comment_data = {\n",
        "                                    'comment_id': comment.id,\n",
        "                                    'post_id': post.id,\n",
        "                                    'author': str(comment.author) if comment.author else '[deleted]',\n",
        "                                    'body': comment_body,\n",
        "                                    'body_length': len(comment.body),\n",
        "                                    'score': comment.score,\n",
        "                                    'created_utc': datetime.fromtimestamp(comment.created_utc).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "                                    'subreddit': subreddit_name,\n",
        "                                    'is_submitter': comment.is_submitter,\n",
        "                                    'gilded': comment.gilded\n",
        "                                }\n",
        "                                all_comments.append(comment_data)\n",
        "                                comment_count += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"⚠️ Помилка парсингу коментарів: {e}\")\n",
        "                \n",
        "                post_count += 1\n",
        "            \n",
        "            print(f\"✅ r/{subreddit_name}: {post_count} постів, {len([c for c in all_comments if c['subreddit'] == subreddit_name])} коментарів\")\n",
        "            time.sleep(1)  # Затримка між сабреддітами\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ Помилка парсингу r/{subreddit_name}: {e}\")\n",
        "    \n",
        "    return pd.DataFrame(all_posts), pd.DataFrame(all_comments)\n",
        "\n",
        "# Запуск парсингу\n",
        "print(\"🚀 Початок парсингу Reddit...\")\n",
        "posts_df, comments_df = parse_reddit_data(\n",
        "    TARGET_SUBREDDITS, \n",
        "    POSTS_PER_SUBREDDIT, \n",
        "    SORT_BY, \n",
        "    COMMENTS_PER_POST, \n",
        "    TEXT_LIMIT\n",
        ")\n",
        "\n",
        "print(f\"\\n📊 Результати парсингу:\")\n",
        "print(f\"📝 Постів: {len(posts_df)}\")\n",
        "print(f\"💬 Коментарів: {len(comments_df)}\")\n",
        "print(f\"🏷️ Сабреддітів: {posts_df['subreddit'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 📈 Базова аналітика\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Відображення топ постів\n",
        "print(\"🏆 ТОП-10 ПОСТІВ ЗА РЕЙТИНГОМ:\")\n",
        "top_posts = posts_df.nlargest(10, 'score')[['title', 'score', 'subreddit', 'num_comments']]\n",
        "for i, (_, post) in enumerate(top_posts.iterrows(), 1):\n",
        "    print(f\"{i:2d}. {post['title'][:60]}... (Score: {post['score']}, r/{post['subreddit']})\")\n",
        "\n",
        "print(f\"\\n💬 ТОП-5 ПОСТІВ ЗА КОМЕНТАРЯМИ:\")\n",
        "top_commented = posts_df.nlargest(5, 'num_comments')[['title', 'num_comments', 'subreddit', 'score']]\n",
        "for i, (_, post) in enumerate(top_commented.iterrows(), 1):\n",
        "    print(f\"{i}. {post['title'][:50]}... ({post['num_comments']} коментарів, r/{post['subreddit']})\")\n",
        "\n",
        "# Статистика по сабреддітам\n",
        "print(f\"\\n📊 СТАТИСТИКА ПО САБРЕДДІТАМ:\")\n",
        "subreddit_stats = posts_df.groupby('subreddit').agg({\n",
        "    'score': ['mean', 'max'],\n",
        "    'num_comments': ['mean', 'max'],\n",
        "    'post_id': 'count'\n",
        "}).round(1)\n",
        "\n",
        "for subreddit in subreddit_stats.index:\n",
        "    stats = subreddit_stats.loc[subreddit]\n",
        "    print(f\"r/{subreddit}: {stats[('post_id', 'count')]} постів, середній рейтинг: {stats[('score', 'mean')]}, макс: {stats[('score', 'max')]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🎭 Конфігурації для різних стилів контенту\n",
        "\n",
        "Оберіть одну з готових конфігурацій залежно від бажаного стилю:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Конфігурації для різних стилів контенту\n",
        "CONTENT_STYLES = {\n",
        "    \"human_relatable\": {\n",
        "        \"description\": \"🧑‍💻 Людяний та співчутливий стиль\",\n",
        "        \"model\": \"anthropic/claude-3-haiku\",\n",
        "        \"temperature\": 0.8,\n",
        "        \"max_tokens\": 2000,\n",
        "        \"focus\": \"особисті історії, проблеми, співпереживання\"\n",
        "    },\n",
        "    \n",
        "    \"humorous_casual\": {\n",
        "        \"description\": \"😄 Гумористичний та невимушений\",\n",
        "        \"model\": \"openai/gpt-4o-mini\",\n",
        "        \"temperature\": 0.9,\n",
        "        \"max_tokens\": 1800,\n",
        "        \"focus\": \"жарти, мемі, легкий тон, Reddit-сленг\"\n",
        "    },\n",
        "    \n",
        "    \"technical_engaging\": {\n",
        "        \"description\": \"🔧 Технічний але захоплюючий\",\n",
        "        \"model\": \"google/gemini-2.0-flash-exp\",\n",
        "        \"temperature\": 0.6,\n",
        "        \"max_tokens\": 2500,\n",
        "        \"focus\": \"технічні відкриття, поради, TIL формат\"\n",
        "    },\n",
        "    \n",
        "    \"discussion_starter\": {\n",
        "        \"description\": \"💬 Провокує дискусії\",\n",
        "        \"model\": \"anthropic/claude-3-sonnet\",\n",
        "        \"temperature\": 0.7,\n",
        "        \"max_tokens\": 2200,\n",
        "        \"focus\": \"спірні думки, питання, дебати\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# Виберіть стиль (змініть ключ для іншого стилю)\n",
        "SELECTED_STYLE = \"human_relatable\"  # або \"humorous_casual\", \"technical_engaging\", \"discussion_starter\"\n",
        "\n",
        "# Застосування обраного стилю\n",
        "style_config = CONTENT_STYLES[SELECTED_STYLE]\n",
        "print(f\"🎭 Обраний стиль: {style_config['description']}\")\n",
        "print(f\"🎯 Фокус: {style_config['focus']}\")\n",
        "\n",
        "# Оновлення глобальних налаштувань\n",
        "LLM_MODEL = style_config['model']\n",
        "MAX_TOKENS = style_config['max_tokens']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🧠 LLM Аналіз та генерація контенту\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_and_generate_content(posts_df):\n",
        "    \"\"\"\n",
        "    Аналіз даних через LLM та генерація нових ідей постів\n",
        "    \"\"\"\n",
        "    \n",
        "    # Константи для LLM\n",
        "    ANALYSIS_RULES = \"\"\"Уяви, що ти досвідчений Reddit-користувач з багаторічним стажем, який інтуїтивно відчуває, що \"зайде\" у спільноті. Ти вмієш помічати тонкі нюанси, що роблять пост вірусним.\n",
        "\n",
        "    Твоє завдання як справжнього реддітора:\n",
        "    1. 👀 Помітити повторювані теми, формати чи жарти — що зараз набирає популярність?\n",
        "    2. 🧠 Розпізнати, чому деякі пости стали хітами — особливий стиль, емоція, особиста історія, гумор?\n",
        "    3. ✨ Вигадати нові пости, які звучать натурально, як від реальної людини з справжніми емоціями\n",
        "    \n",
        "    Генеруй пости, які:\n",
        "    - Мають особистий дотик (досвід, проблема, відкриття)\n",
        "    - Викликають емоції (здивування, співпереживання, захоплення, гумор)\n",
        "    - Звучать як жива людина, а не бот\n",
        "    - Використовують природну Reddit-мову та тон спільноти\n",
        "    \n",
        "    ⚠️ ВАЖЛИВІ ОБМЕЖЕННЯ:\n",
        "    - НЕ вигадуй конкретних подій, які точно не відбувалися\n",
        "    - Якщо контент побудований на припущеннях, сформулюй це як особисту думку або гіпотезу\n",
        "    - Використовуй емодзі помірно: не більше 1-2 в одному пості, тільки для підсилення емоції\n",
        "    - Один з двох постів ОБОВ'ЯЗКОВО має бути особистою історією/спостереженням, а не загальною думкою\n",
        "    \n",
        "    Формат відповіді JSON:\n",
        "    {\n",
        "        \"trends\": [\"тренд1 (з поясненням чому він популярний)\", \"тренд2\", \"тренд3\", \"тренд4\", \"тренд5\"],\n",
        "        \"success_factors\": [\"фактор1 (що конкретно працює)\", \"фактор2\", \"фактор3\"],\n",
        "        \"post_ideas\": [\n",
        "            {\n",
        "                \"title\": \"Заголовок поста (природний, як писала б жива людина)\",\n",
        "                \"content\": \"Основний текст поста з особистим тоном, емоціями та деталями, що викликають відгук (2-3 абзаци)\",\n",
        "                \"reasoning\": \"Чому цей пост зацепить людей - психологія, емоції, актуальність\",\n",
        "                \"tags\": [\"тег1\", \"тег2\", \"тег3\"],\n",
        "                \"estimated_engagement\": \"high/medium/low\",\n",
        "                \"post_type\": \"особиста історія/питання/гумор/поради/дискусія\",\n",
        "                \"is_personal_story\": true,\n",
        "                \"safety_check\": \"Підтверджую, що не вигадую конкретних фактів\"\n",
        "            },\n",
        "            {\n",
        "                \"title\": \"Другий заголовок (інший тон та тип - обов'язково відрізняється від першого)\",\n",
        "                \"content\": \"Другий пост з іншим підходом - якщо перший особиста історія, то цей може бути питанням чи думкою\",\n",
        "                \"reasoning\": \"Інша психологічна мотивація для залучення аудиторії\",\n",
        "                \"tags\": [\"тег1\", \"тег2\", \"тег3\"],\n",
        "                \"estimated_engagement\": \"high/medium/low\",\n",
        "                \"post_type\": \"особиста історія/питання/гумор/поради/дискусія\",\n",
        "                \"is_personal_story\": false,\n",
        "                \"safety_check\": \"Підтверджую, що використовую особисті думки та гіпотези\"\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    Пиши як реальна людина, яка ділиться думкою з другом у Reddit. Без пафосу. Без маркетингу. Прямо, щиро, іноді з самоіронією.\n",
        "    \n",
        "    💡 ПРИКЛАДИ ПРИРОДНИХ REDDIT-ЗАГОЛОВКІВ:\n",
        "    • Особиста історія: \"Щойно зрозумів, що 3 роки писав код неправильно...\" / \"Мій менеджер сказав, що Python повільний. Довів йому протилежне\"\n",
        "    • Проблема: \"Хтось ще думає, що GitHub Copilot робить нас лінивішими?\" / \"Як ви справляєтесь з синдромом самозванця в IT?\"\n",
        "    • Відкриття: \"TIL що можна робити це в Python одним рядком\" / \"Простий трюк, який прискорив мій код у 10 разів\"\n",
        "    • Гумор: \"Коли бачиш код, який писав 6 місяців тому\" / \"Мій код працює, але я не знаю чому\"\n",
        "    • Дискусія: \"Непопулярна думка: TypeScript переоцінений\" / \"Змініть мою думку: Python не підходить для великих проектів\"\n",
        "    \n",
        "    Використовуй природні фрази, емоції та Reddit-сленг. Відповідай ТІЛЬКИ валідним JSON.\"\"\"\n",
        "    \n",
        "    async def analyze_single_subreddit(subreddit_name, subreddit_posts, client, semaphore):\n",
        "        @backoff.on_exception(backoff.expo, (openai.APIError, openai.RateLimitError, asyncio.TimeoutError), max_tries=3)\n",
        "        async def call():\n",
        "            async with semaphore:\n",
        "                # Підготовка даних для аналізу\n",
        "                top_posts = subreddit_posts.nlargest(5, 'score')\n",
        "                avg_score = subreddit_posts['score'].mean()\n",
        "                avg_comments = subreddit_posts['num_comments'].mean()\n",
        "                \n",
        "                # Витягування популярних слів\n",
        "                all_titles = ' '.join(subreddit_posts['title'].tolist()).lower()\n",
        "                words = re.findall(r'\\\\b[a-zA-Zа-яА-Я]{3,}\\\\b', all_titles)\n",
        "                common_words = [word for word, count in Counter(words).most_common(10)]\n",
        "                \n",
        "                user_prompt = f\"\"\"Ось підбірка постів з r/{subreddit_name}. Подивись, що тут працює!\n",
        "                \n",
        "                📊 Статистика спільноти:\n",
        "                • Постів проаналізовано: {len(subreddit_posts)}\n",
        "                • Середній рейтинг: {avg_score:.1f} (показує, наскільки активна спільнота)\n",
        "                • Середня кількість коментарів: {avg_comments:.1f} (рівень дискусій)\n",
        "                \n",
        "                🏆 Найпопулярніші пости (що реально зайшло людям):\n",
        "                {chr(10).join([f\"   {i+1}. \\\"{row['title']}\\\" — {row['score']} апвоутів 🔥\" for i, (_, row) in enumerate(top_posts.iterrows())])}\n",
        "                \n",
        "                🔥 Слова, що часто з'являються: {', '.join(common_words[:10])}\n",
        "                (це підказки про те, що цікавить спільноту)\n",
        "                \n",
        "                Тепер твоє завдання як досвідченого реддітора:\n",
        "                Подумай — що робить ці пости успішними? Яка емоція, проблема чи цікавинка зачепила людей?\n",
        "                \n",
        "                Згенеруй 2 ідеї постів для r/{subreddit_name}, які:\n",
        "                • Звучать як від справжньої людини з реальною проблемою/досвідом\n",
        "                • Мають потенціал викликати емоції та дискусії  \n",
        "                • Вписуються в культуру цієї спільноти\n",
        "                • НЕ повторюють існуючі пости, а пропонують щось свіже\n",
        "                \n",
        "                ⚠️ ОБОВ'ЯЗКОВІ ВИМОГИ:\n",
        "                • Один пост має бути особистою історією/досвідом (не загальною думкою)\n",
        "                • Не вигадуй конкретних фактів - використовуй гіпотези та особисті думки\n",
        "                • Емодзі тільки для підсилення емоції (максимум 1-2 на пост)\"\"\"\n",
        "                \n",
        "                # Перший запит\n",
        "                response = await asyncio.wait_for(\n",
        "                    client.chat.completions.create(\n",
        "                        model=LLM_MODEL,\n",
        "                        messages=[\n",
        "                            {\"role\": \"system\", \"content\": ANALYSIS_RULES},\n",
        "                            {\"role\": \"user\", \"content\": user_prompt}\n",
        "                        ],\n",
        "                        temperature=style_config['temperature'],\n",
        "                        max_tokens=MAX_TOKENS,\n",
        "                        stream=False\n",
        "                    ),\n",
        "                    timeout=TIMEOUT_SECONDS\n",
        "                )\n",
        "                \n",
        "                result = response.choices[0].message.content.strip()\n",
        "                \n",
        "                # Перевірка на обрізання та догенерація\n",
        "                if ENABLE_CONTINUATION and response.choices[0].finish_reason == 'length':\n",
        "                    print(f\"⚠️ Відповідь обрізана для r/{subreddit_name}, виконую догенерацію...\")\n",
        "                    \n",
        "                    # Догенерація\n",
        "                    continue_response = await asyncio.wait_for(\n",
        "                        client.chat.completions.create(\n",
        "                            model=LLM_MODEL,\n",
        "                            messages=[\n",
        "                                {\"role\": \"system\", \"content\": \"Продовжи JSON відповідь з того місця, де вона була обрізана. Верни ТІЛЬКИ валідний JSON.\"},\n",
        "                                {\"role\": \"user\", \"content\": f\"Обрізана відповідь: {result}\\\\n\\\\nПродовжи та завершити JSON структуру.\"}\n",
        "                            ],\n",
        "                            temperature=style_config['temperature'],\n",
        "                            max_tokens=MAX_TOKENS // 2,\n",
        "                            stream=False\n",
        "                        ),\n",
        "                        timeout=TIMEOUT_SECONDS // 2\n",
        "                    )\n",
        "                    \n",
        "                    # Спроба об'єднати відповіді\n",
        "                    continued_result = continue_response.choices[0].message.content.strip()\n",
        "                    \n",
        "                    # Простий алгоритм об'єднання JSON\n",
        "                    if result.endswith('...') or not result.endswith('}'):\n",
        "                        # Видаляємо незавершені частини та об'єднуємо\n",
        "                        if '\"post_ideas\":' in result and not result.rstrip().endswith(']}'):\n",
        "                            # Знаходимо останню повну структуру\n",
        "                            try:\n",
        "                                # Спробуємо парсити continued_result як повний JSON\n",
        "                                import json\n",
        "                                json.loads(continued_result)\n",
        "                                result = continued_result\n",
        "                            except:\n",
        "                                # Якщо не вдалося, використовуємо оригінальний результат\n",
        "                                pass\n",
        "                \n",
        "                return {\n",
        "                    \"subreddit\": subreddit_name,\n",
        "                    \"result\": result,\n",
        "                    \"finish_reason\": response.choices[0].finish_reason\n",
        "                }\n",
        "        \n",
        "        return await call()\n",
        "    \n",
        "    async def process_all_subreddits(subreddits_data):\n",
        "        client = openai.AsyncOpenAI(\n",
        "            api_key=OPENROUTER_API_KEY,\n",
        "            base_url=\"https://openrouter.ai/api/v1\"\n",
        "        )\n",
        "        semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n",
        "        \n",
        "        tasks = [\n",
        "            analyze_single_subreddit(subreddit, data, client, semaphore)\n",
        "            for subreddit, data in subreddits_data.items()\n",
        "        ]\n",
        "        \n",
        "        results = []\n",
        "        completed = 0\n",
        "        total = len(tasks)\n",
        "        \n",
        "        for task in asyncio.as_completed(tasks):\n",
        "            result = await task\n",
        "            results.append(result)\n",
        "            completed += 1\n",
        "            print(f\"Overall: {completed/total*100:.1f}% | Completed: {completed}/{total}\")\n",
        "        \n",
        "        await client.close()\n",
        "        return results\n",
        "    \n",
        "    # Підготовка даних по сабреддітам\n",
        "    subreddits_data = {}\n",
        "    for subreddit in CONTENT_GENERATION_SUBREDDITS:\n",
        "        subreddit_posts = posts_df[posts_df['subreddit'] == subreddit]\n",
        "        if len(subreddit_posts) > 0:\n",
        "            subreddits_data[subreddit] = subreddit_posts\n",
        "    \n",
        "    print(f\"🧠 Запуск LLM аналізу для {len(subreddits_data)} сабреддітів...\")\n",
        "    \n",
        "    # Запуск асинхронного аналізу\n",
        "    loop = asyncio.get_event_loop()\n",
        "    results = loop.run_until_complete(process_all_subreddits(subreddits_data))\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Запуск аналізу\n",
        "analysis_results = analyze_and_generate_content(posts_df)\n",
        "\n",
        "print(f\"\\n✅ LLM аналіз завершено для {len(analysis_results)} сабреддітів\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 💡 Результати генерації контенту\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функція для покращеного парсингу JSON\n",
        "def parse_json_response(response_text, subreddit_name):\n",
        "    \"\"\"\n",
        "    Покращений парсинг JSON відповідей з обробкою різних форматів\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Спочатку спробуємо парсити весь текст як JSON\n",
        "        data = json.loads(response_text)\n",
        "        return data, True\n",
        "    except json.JSONDecodeError:\n",
        "        pass\n",
        "    \n",
        "    # Спробуємо знайти JSON блок у тексті\n",
        "    json_patterns = [\n",
        "        r'```json\\\\s*({.*?})\\\\s*```',  # JSON у markdown блоці\n",
        "        r'({[^{}]*(?:{[^{}]*}[^{}]*)*})',  # Простий JSON блок\n",
        "        r'({.*})',  # Будь-який блок у фігурних дужках\n",
        "    ]\n",
        "    \n",
        "    for pattern in json_patterns:\n",
        "        matches = re.findall(pattern, response_text, re.DOTALL)\n",
        "        for match in matches:\n",
        "            try:\n",
        "                # Очищуємо JSON від можливих проблем\n",
        "                clean_json = match.strip()\n",
        "                \n",
        "                # Виправляємо поширені проблеми\n",
        "                clean_json = re.sub(r',\\\\s*}', '}', clean_json)  # Видаляємо зайві коми\n",
        "                clean_json = re.sub(r',\\\\s*]', ']', clean_json)  # Видаляємо зайві коми в масивах\n",
        "                \n",
        "                # Якщо JSON обрізаний, спробуємо завершити його\n",
        "                if not clean_json.endswith('}') and '\"post_ideas\"' in clean_json:\n",
        "                    # Знаходимо останню повну ідею\n",
        "                    ideas_start = clean_json.find('\"post_ideas\": [')\n",
        "                    if ideas_start != -1:\n",
        "                        # Рахуємо відкриті дужки\n",
        "                        bracket_count = 0\n",
        "                        last_complete_pos = ideas_start\n",
        "                        \n",
        "                        for i, char in enumerate(clean_json[ideas_start:], ideas_start):\n",
        "                            if char == '{':\n",
        "                                bracket_count += 1\n",
        "                            elif char == '}':\n",
        "                                bracket_count -= 1\n",
        "                                if bracket_count == 0:\n",
        "                                    last_complete_pos = i + 1\n",
        "                        \n",
        "                        # Обрізаємо до останньої повної структури\n",
        "                        if last_complete_pos > ideas_start:\n",
        "                            before_ideas = clean_json[:ideas_start + len('\"post_ideas\": [')]\n",
        "                            ideas_part = clean_json[ideas_start + len('\"post_ideas\": ['):last_complete_pos]\n",
        "                            clean_json = before_ideas + ideas_part + ']}'\n",
        "                \n",
        "                data = json.loads(clean_json)\n",
        "                return data, True\n",
        "                \n",
        "            except json.JSONDecodeError:\n",
        "                continue\n",
        "    \n",
        "    # Якщо нічого не вдалося парсити, повертаємо None\n",
        "    return None, False\n",
        "\n",
        "# Обробка та відображення результатів\n",
        "generated_ideas = []\n",
        "\n",
        "for result in analysis_results:\n",
        "    subreddit = result['subreddit']\n",
        "    response_text = result['result']\n",
        "    finish_reason = result.get('finish_reason', 'unknown')\n",
        "    \n",
        "    print(f\"\\n🎯 РЕЗУЛЬТАТИ ДЛЯ r/{subreddit}:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    if finish_reason == 'length':\n",
        "        print(\"⚠️ Відповідь була обрізана через ліміт токенів\")\n",
        "    \n",
        "    # Спроба покращеного парсингу\n",
        "    data, success = parse_json_response(response_text, subreddit)\n",
        "    \n",
        "    if success and data:\n",
        "        # Відображення трендів\n",
        "        if 'trends' in data:\n",
        "            print(f\"📈 Тренди ({len(data['trends'])}): {', '.join(data['trends'])}\")\n",
        "        \n",
        "        # Відображення факторів успіху\n",
        "        if 'success_factors' in data:\n",
        "            print(f\"🎯 Фактори успіху ({len(data['success_factors'])}): {', '.join(data['success_factors'])}\")\n",
        "        \n",
        "        # Відображення ідей постів\n",
        "        if 'post_ideas' in data and data['post_ideas']:\n",
        "            print(f\"\\n💡 ЗГЕНЕРОВАНІ ІДЕЇ ({len(data['post_ideas'])}):\\\\n\")\n",
        "            \n",
        "            # Валідація вимог\n",
        "            personal_stories = sum(1 for idea in data['post_ideas'] if idea.get('is_personal_story', False))\n",
        "            if personal_stories == 0:\n",
        "                print(\"⚠️ УВАГА: Жодна ідея не позначена як особиста історія!\")\n",
        "            elif personal_stories >= 1:\n",
        "                print(f\"✅ Перевірка пройдена: {personal_stories} особистих історій знайдено\")\n",
        "            print()\n",
        "            \n",
        "            for i, idea in enumerate(data['post_ideas'], 1):\n",
        "                print(f\"💡 Ідея {i}:\")\n",
        "                print(f\"  📝 Заголовок: {idea.get('title', 'N/A')}\")\n",
        "                \n",
        "                content = idea.get('content', 'N/A')\n",
        "                if len(content) > 150:\n",
        "                    print(f\"  📄 Контент: {content[:150]}...\")\n",
        "                else:\n",
        "                    print(f\"  📄 Контент: {content}\")\n",
        "                \n",
        "                print(f\"  🎯 Обґрунтування: {idea.get('reasoning', 'N/A')}\")\n",
        "                print(f\"  🏷️ Теги: {', '.join(idea.get('tags', []))}\")\n",
        "                print(f\"  📈 Прогноз залученості: {idea.get('estimated_engagement', 'N/A')}\")\n",
        "                \n",
        "                # Додаткові перевірки безпеки та типу\n",
        "                post_type = idea.get('post_type', 'N/A')\n",
        "                is_personal = idea.get('is_personal_story', False)\n",
        "                safety_check = idea.get('safety_check', 'N/A')\n",
        "                \n",
        "                print(f\"  🎭 Тип поста: {post_type}\")\n",
        "                print(f\"  👤 Особиста історія: {'✅ Так' if is_personal else '❌ Ні'}\")\n",
        "                print(f\"  🛡️ Перевірка безпеки: {safety_check}\")\n",
        "                print()\n",
        "                \n",
        "                # Збереження для експорту\n",
        "                idea_data = idea.copy()\n",
        "                idea_data['target_subreddit'] = subreddit\n",
        "                generated_ideas.append(idea_data)\n",
        "        else:\n",
        "            print(\"⚠️ Не знайдено ідей постів у відповіді\")\n",
        "            \n",
        "    else:\n",
        "        print(f\"⚠️ Не вдалося парсити JSON, показую сирий текст:\")\n",
        "        print(\"=\" * 30)\n",
        "        print(response_text[:800] + (\"...\" if len(response_text) > 800 else \"\"))\n",
        "        print(\"=\" * 30)\n",
        "        \n",
        "        # Спробуємо витягти хоча б частину інформації\n",
        "        if \"trends\" in response_text.lower():\n",
        "            print(\"\\\\n📈 Знайдено згадки трендів у тексті\")\n",
        "        if \"post_ideas\" in response_text.lower():\n",
        "            print(\"💡 Знайдено згадки ідей постів у тексті\")\n",
        "\n",
        "print(f\"\\n🎉 Загалом згенеровано {len(generated_ideas)} ідей постів!\")\n",
        "\n",
        "if len(generated_ideas) == 0:\n",
        "    print(\"\\\\n💡 ПОРАДИ ДЛЯ ПОКРАЩЕННЯ РЕЗУЛЬТАТІВ:\")\n",
        "    print(\"1. Збільште MAX_TOKENS до 3000+ у глобальних налаштуваннях\")\n",
        "    print(\"2. Спробуйте іншу LLM модель (anthropic/claude-3-haiku)\")\n",
        "    print(\"3. Зменште кількість сабреддітів для тестування\")\n",
        "    print(\"4. Перевірте якість інтернет з'єднання\")\n",
        "    print(\"5. Спробуйте запустити аналіз ще раз\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 💾 Збереження результатів\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Створення timestamp для файлів\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "# Збереження постів у Excel\n",
        "# posts_filename = f\"reddit_posts_{timestamp}.xlsx\"\n",
        "# with pd.ExcelWriter(posts_filename, engine='openpyxl') as writer:\n",
        "#     posts_df.to_excel(writer, sheet_name='Posts', index=False)\n",
        "#     if len(comments_df) > 0:\n",
        "#         comments_df.to_excel(writer, sheet_name='Comments', index=False)\n",
        "    \n",
        "#     # Статистика по сабреддітам\n",
        "#     subreddit_stats = posts_df.groupby('subreddit').agg({\n",
        "#         'score': ['mean', 'max', 'min'],\n",
        "#         'num_comments': ['mean', 'max'],\n",
        "#         'post_id': 'count',\n",
        "#         'upvote_ratio': 'mean'\n",
        "#     }).round(2)\n",
        "#     subreddit_stats.to_excel(writer, sheet_name='Subreddit_Stats')\n",
        "\n",
        "# print(f\"✅ Пости збережено: {posts_filename}\")\n",
        "\n",
        "# Збереження згенерованих ідей\n",
        "if generated_ideas:\n",
        "    ideas_filename = f\"generated_ideas_{timestamp}.json\"\n",
        "    \n",
        "    export_data = {\n",
        "        \"metadata\": {\n",
        "            \"generated_at\": datetime.now().isoformat(),\n",
        "            \"total_ideas\": len(generated_ideas),\n",
        "            \"target_subreddits\": CONTENT_GENERATION_SUBREDDITS,\n",
        "            \"source_posts\": len(posts_df),\n",
        "            \"llm_model\": LLM_MODEL\n",
        "        },\n",
        "        \"generated_ideas\": generated_ideas,\n",
        "        \"source_analysis\": {\n",
        "            \"total_posts\": len(posts_df),\n",
        "            \"avg_score\": float(posts_df['score'].mean()),\n",
        "            \"avg_comments\": float(posts_df['num_comments'].mean()),\n",
        "            \"subreddits\": posts_df['subreddit'].unique().tolist()\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    with open(ideas_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(export_data, f, ensure_ascii=False, indent=2)\n",
        "    \n",
        "    print(f\"✅ Ідеї збережено: {ideas_filename}\")\n",
        "\n",
        "print(f\"\\n🎉 АНАЛІЗ ЗАВЕРШЕНО!\")\n",
        "print(f\"📁 Створені файли:\")\n",
        "# print(f\"  📊 {posts_filename} - Дані постів та коментарів\")\n",
        "if generated_ideas:\n",
        "    print(f\"  💡 {ideas_filename} - Згенеровані ідеї (JSON)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 🔍 Додаткова аналітика\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Аналіз найкращих часів для постингу\n",
        "posts_df['hour'] = pd.to_datetime(posts_df['created_utc']).dt.hour\n",
        "posts_df['day_of_week'] = pd.to_datetime(posts_df['created_utc']).dt.day_name()\n",
        "\n",
        "print(\"⏰ НАЙКРАЩІ ГОДИНИ ДЛЯ ПОСТИНГУ (за рейтингом):\")\n",
        "hourly_stats = posts_df.groupby('hour')['score'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
        "for hour, stats in hourly_stats.head(5).iterrows():\n",
        "    print(f\"  {hour:02d}:00 - Середній рейтинг: {stats['mean']:.1f} ({stats['count']} постів)\")\n",
        "\n",
        "print(\"\\n📅 НАЙКРАЩІ ДНІ ТИЖНЯ:\")\n",
        "daily_stats = posts_df.groupby('day_of_week')['score'].agg(['mean', 'count']).sort_values('mean', ascending=False)\n",
        "for day, stats in daily_stats.iterrows():\n",
        "    print(f\"  {day}: {stats['mean']:.1f} середній рейтинг ({stats['count']} постів)\")\n",
        "\n",
        "# Аналіз довжини заголовків\n",
        "posts_df['title_length'] = posts_df['title'].str.len()\n",
        "print(f\"\\n📝 АНАЛІЗ ЗАГОЛОВКІВ:\")\n",
        "print(f\"  Середня довжина: {posts_df['title_length'].mean():.1f} символів\")\n",
        "print(f\"  Оптимальна довжина (топ 25%): {posts_df.nlargest(len(posts_df)//4, 'score')['title_length'].mean():.1f} символів\")\n",
        "\n",
        "# Кореляційний аналіз\n",
        "numeric_cols = ['score', 'num_comments', 'upvote_ratio', 'title_length', 'selftext_length']\n",
        "correlation_matrix = posts_df[numeric_cols].corr()\n",
        "\n",
        "print(f\"\\n🔗 КОРЕЛЯЦІЇ (з рейтингом):\")\n",
        "score_correlations = correlation_matrix['score'].sort_values(ascending=False)[1:]  # Виключаємо саму себе\n",
        "for feature, corr in score_correlations.items():\n",
        "    print(f\"  {feature}: {corr:.3f}\")\n",
        "\n",
        "print(f\"\\n📊 Аналітика завершена!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
